<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>LiveAvatar Viewer</title>

  <!-- LiveKit JS SDK (UMD) via cdnjs -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/livekit-client/2.15.7/livekit-client.umd.min.js"></script>

  <style>
    body { margin: 0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial; background: #0b0b0b; color: #eee; }
    .wrap { display: flex; flex-direction: column; align-items: center; justify-content: flex-start; padding: 14px; gap: 10px; }
    .title { font-size: 14px; opacity: 0.9; }
    .stage { width: 100%; max-width: 720px; aspect-ratio: 16/9; background: #111; border-radius: 16px; overflow: hidden; position: relative; }
    video { width: 100%; height: 100%; object-fit: cover; background: #111; }
    .status { font-size: 12px; opacity: 0.9; }
    .status span { opacity: 0.8; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="title"><b>__AVATAR_NAME__</b> · Live session</div>
    <div class="stage">
      <video id="avatarVideo" autoplay playsinline></video>
    </div>
    <div class="status" id="status">Connecting…</div>
  </div>

<script>
(function () {
  const LIVEKIT_URL = "__LIVEKIT_URL__";
  const LIVEKIT_TOKEN = "__LIVEKIT_TOKEN__";
  const SPEAK = __SPEAK_PAYLOAD_JSON__;

  const statusEl = document.getElementById("status");
  const avatarVideo = document.getElementById("avatarVideo");

  const LK = window.LiveKitClient;
  if (!LK) {
    statusEl.textContent = "LiveKitClient not loaded.";
    return;
  }

  // --- Helpers ---
  const enc = new TextEncoder();

  function setStatus(msg) {
    statusEl.textContent = msg;
  }

  // LiveAvatar FULL-mode command event sender.
  // Docs only specify event name + data schema (text).
  // In practice, many event systems expect a "type" field.
  // We send {type: <event>, ...data }.
  function buildCommand(eventName, dataObj) {
    return Object.assign({ type: eventName }, (dataObj || {}));
  }

  async function publishCommand(room, eventName, dataObj) {
    const payload = buildCommand(eventName, dataObj);
    const bytes = enc.encode(JSON.stringify(payload));
    // RELIABLE is better for commands.
    await room.localParticipant.publishData(bytes, LK.DataPacket_Kind.RELIABLE);
  }

  // --- LiveKit room ---
  const room = new LK.Room({
    adaptiveStream: true,
    dynacast: true,
    // autoSubscribe=true so we receive the avatar tracks
  });

  // Track management: attach ONLY remote avatar video/audio.
  function attachRemoteTrack(track) {
    try {
      if (track.kind === "video") {
        track.attach(avatarVideo);
      } else if (track.kind === "audio") {
        // Attach audio to hidden element
        const a = track.attach();
        a.style.display = "none";
        document.body.appendChild(a);
      }
    } catch (e) {
      console.warn("attach failed", e);
    }
  }

  room.on(LK.RoomEvent.TrackSubscribed, (track, pub, participant) => {
    // The HeyGen/LiveAvatar participant will publish video + audio
    attachRemoteTrack(track);
  });

  room.on(LK.RoomEvent.ParticipantConnected, (p) => {
    // For debugging; not shown in UI.
    // console.log("participant connected", p.identity);
  });

  room.on(LK.RoomEvent.Disconnected, () => {
    setStatus("Disconnected.");
  });

  // Listen for server events (optional)
  room.on(LK.RoomEvent.DataReceived, (payload, participant, kind) => {
    try {
      const txt = new TextDecoder().decode(payload);
      // LiveAvatar server events are emitted into the room; useful for debugging.
      // console.log("data recv", txt);
    } catch (_) {}
  });

  async function connect() {
    setStatus("Connecting to LiveKit…");
    await room.connect(LIVEKIT_URL, LIVEKIT_TOKEN, { autoSubscribe: true });

    // IMPORTANT: We do NOT enable camera/mic.
    // This prevents the user's video tile + permission prompts.
    // (We never call createLocalTracks / setCameraEnabled / setMicrophoneEnabled)

    setStatus("Connected. Waiting for avatar tracks…");

    // If remote avatar already published tracks before we subscribed:
    room.remoteParticipants.forEach((p) => {
      p.trackPublications.forEach((pub) => {
        if (pub.isSubscribed && pub.track) attachRemoteTrack(pub.track);
      });
    });

    // Speak logic
    const text = (SPEAK.text || "").trim();
    if (!text) return;

    // Auto-speak, or speak when nonce increments (Streamlit triggers iframe reload).
    if (SPEAK.auto || (SPEAK.nonce && SPEAK.nonce > 0)) {
      await doSpeak(text);
    }

    // Stress mode: repeat speak_text N times
    if (SPEAK.stress) {
      const repeat = Math.max(1, Number(SPEAK.repeat || 1));
      const interval = Math.max(250, Number(SPEAK.interval_ms || 1000));

      let i = 0;
      const timer = setInterval(async () => {
        i += 1;
        try {
          await doSpeak(text);
          setStatus(`Speaking… (${i}/${repeat})`);
        } catch (e) {
          console.error(e);
          setStatus("Speak failed (see console).");
          clearInterval(timer);
        }
        if (i >= repeat) {
          clearInterval(timer);
          setStatus("Done.");
        }
      }, interval);
    }
  }

  async function doSpeak(text) {
    // Primary command: avatar.speak_text
    // Event data schema: {"text": string}
    await publishCommand(room, "avatar.speak_text", { text });
  }

  connect().catch((e) => {
    console.error(e);
    setStatus("Connect failed (see console).");
  });

})();
</script>
</body>
</html>
